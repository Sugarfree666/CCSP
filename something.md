# 毕业设计资料

[nuolade/disease-kb: 常见疾病相关信息构建knowledge graph](https://github.com/nuolade/disease-kb)

[honeyandme/RAGQnASystem: 本项目设计了一个基于 RAG 与大模型技术的医疗问答系统，利用 DiseaseKG 数据集与 Neo4j 构 建知识图谱，结合 BERT 的命名实体识别和 34b 大模型的意图识别，通过精确的知识检索和问答生成， 提升系统在医疗咨询中的性能，解决大模型在医疗领域应用的可靠性问题。](https://github.com/honeyandme/RAGQnASystem?tab=readme-ov-file)



# ideas？

## GraphFlow与Beyond the answer

> 对推理路径进行PSE离线打分，作为Reward。

​	可以对数据集进行PSE离线打分，作为Reward。在多跳问答或图检索中，模型不仅要找到可以支持回答的正确路径，这个路径还应该尽可能的合理。

1. GraphFlow 的目标是学习一个生成路径的策略，使采样出的路径分布与其质量成比例。但是reward只使用二值或者粗略奖励信号无法区分“好的程度”
2. PSE 能告诉我们一条路径“推理得好不好”，而 GraphFlow 的 F(s) 则需要一个高质量的信号告诉它“该学哪些路径”。这两者**刚好形成互补**。





## **检索时用普通图转化成超图来增强LLM？**





## 从静态问答到反事实推理

​	现有RAG系统擅长回答**静态事实类问题**：比如X是什么？Y在哪一年发生的？在真实场景中还有一些问题是：

> 如果某件事情发生or不发生，会导致什么？

​	这类问题常常不存在知识库中，因此传统RAG只能检索到相关信息，无法模拟具体推演过程。能不能让RAG不只是取相关资料，还要动态模拟一个被扰动的知识库。

相关论文：



## 解决知识冲突

> 问题： 用户问“A公司的营收是多少？”
>
> 知识库：财报显示营收100亿，新闻报道说80亿，分析师说是90亿。

普通 RAG 会混淆或随机选一个。不是给出一个数字，而是生成一段解释：“关于A公司营收存在争议，财报口径为100亿，但如果扣除XX业务，新闻报道认为是80亿。”



## 否定性问题判定

知识库中没有提到的东西，LLM非常容易产生幻觉去填补空白。

> 解决的目标问题是：区分“由于缺失数据导致的不知道”和“逻辑上推导出的不存在”
